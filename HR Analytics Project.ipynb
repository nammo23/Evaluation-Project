{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bad5b30",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1209943872.py, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 41\u001b[1;36m\u001b[0m\n\u001b[1;33m    Rows: 14999 | Columns: 10\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "sns.set(style='white')\n",
    "\n",
    "from sklearn import preprocessing \n",
    "\n",
    "from scipy.stats import skew, boxcox_normmax \n",
    "from scipy.special import boxcox1p \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn import model_selection \n",
    "from sklearn.feature_selection import RFE, RFECV \n",
    "\n",
    "hr = pd.read_csv('https://raw.githubusercontent.com/ashomah/HR-Analytics/master/assets/data/turnover.csv')\n",
    "hr.head()\n",
    "\n",
    "print('Rows:', hr.shape[0], '| Columns:', hr.shape[1])\n",
    "\n",
    "def df_desc(df):\n",
    "    import pandas as pd\n",
    "    desc = pd.DataFrame({'dtype': df.dtypes,\n",
    "                         'NAs': df.isna().sum(),\n",
    "                         'Numerical': (df.dtypes != 'object') & (df.apply(lambda column: column == 0).sum() + df.apply(lambda column: column == 1).sum() != len(df)),\n",
    "                         'Boolean': df.apply(lambda column: column == 0).sum() + df.apply(lambda column: column == 1).sum() == len(df),\n",
    "                         'Categorical': df.dtypes == 'object',\n",
    "                        })\n",
    "    return desc\n",
    "\n",
    "df_desc(hr)\n",
    "\n",
    "print('Rows:', hr.shape[0], '| Columns:', hr.shape[1])\n",
    "Rows: 14999 | Columns: 10\n",
    "# Describe each variable\n",
    "def df_desc(df):\n",
    "    import pandas as pd\n",
    "    desc = pd.DataFrame({'dtype': df.dtypes,\n",
    "                         'NAs': df.isna().sum(),\n",
    "                         'Numerical': (df.dtypes != 'object') & (df.apply(lambda column: column == 0).sum() + df.apply(lambda column: column == 1).sum() != len(df)),\n",
    "                         'Boolean': df.apply(lambda column: column == 0).sum() + df.apply(lambda column: column == 1).sum() == len(df),\n",
    "                         'Categorical': df.dtypes == 'object',\n",
    "                        })\n",
    "    return desc\n",
    "\n",
    "df_desc(hr)\n",
    "categories = {'sales': hr['sales'].unique().tolist(),\n",
    " 'salary':hr['salary'].unique().tolist()}\n",
    "for i in sorted(categories.keys()):\n",
    "    print(i+\":\")\n",
    "    print(categories[i])\n",
    "    if i != sorted(categories.keys())[-1] :print(\"\\n\")\n",
    "        \n",
    "hr = hr.rename(index=str, columns={'sales':'department'})\n",
    "hr['left'].value_counts()\n",
    "hr['left'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(hr.corr(), cmap='RdBu', annot=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plot = sns.PairGrid(hr, hue='left', palette=('steelblue', 'crimson'))\n",
    "plot = plot.map_diag(plt.hist)\n",
    "plot = plot.map_offdiag(plt.scatter)\n",
    "plot.add_legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "print('Salary Levels proportions')\n",
    "print(hr['salary'].value_counts()/len(hr)*100)\n",
    "print('\\n')\n",
    "print('Turnover Rate by Salary level')\n",
    "print(hr.groupby('salary')['left'].mean())\n",
    "\n",
    "hr['department'].value_counts()/len(hr)*100\n",
    "\n",
    "hr.groupby('department')['left'].mean().sort_values(ascending=False).plot(kind='bar', color='steelblue')\n",
    "plt.title('Departure Ratio by Department')\n",
    "plt.xlabel('')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot(hr.satisfaction_level,\n",
    "             bins = 20,\n",
    "             color = 'steelblue').axes.set_xlim(min(hr.satisfaction_level),max(hr.satisfaction_level))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(hr['satisfaction_level'],\n",
    "              hue = hr['left'],\n",
    "              palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot(hr.last_evaluation,\n",
    "             bins = 20,\n",
    "             color = 'steelblue').axes.set_xlim(min(hr.last_evaluation),max(hr.last_evaluation))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot(hr.last_evaluation,\n",
    "             bins = 20,\n",
    "             color = 'steelblue').axes.set_xlim(min(hr.last_evaluation),max(hr.last_evaluation))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot(hr.number_project,\n",
    "             bins = 20,\n",
    "             color = 'steelblue').axes.set_xlim(min(hr.number_project),max(hr.number_project))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(hr['number_project'],\n",
    "              hue = hr['left'],\n",
    "              palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.distplot(hr.average_montly_hours,\n",
    "             bins = 20,\n",
    "             color = 'steelblue').axes.set_xlim(min(hr.average_montly_hours),max(hr.average_montly_hours))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(hr['average_montly_hours'],\n",
    "              hue = hr['left'],\n",
    "              palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(hr['time_spend_company'],\n",
    "              hue = hr['left'],\n",
    "              palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(hr['Work_accident'],\n",
    "              hue = hr['left'],\n",
    "              palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(hr['promotion_last_5years'],\n",
    "              hue = hr['left'],\n",
    "              palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "print('Turnover Rate if Promotion:', round(len(hr[(hr['promotion_last_5years']==1)&(hr['left']==1)])/len(hr[(hr['promotion_last_5years']==1)])*100,2),'%')\n",
    "print('Turnover Rate if No Promotion:', round(len(hr[(hr['promotion_last_5years']==0)&(hr['left']==1)])/len(hr[(hr['promotion_last_5years']==0)])*100,2),'%')\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(x=hr.average_montly_hours,\n",
    "            y=hr.number_project,\n",
    "            hue=hr.left,\n",
    "            palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.scatterplot(x=hr.average_montly_hours,\n",
    "            y=hr.number_project,\n",
    "            hue=hr.left,\n",
    "            palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(x=hr.last_evaluation,\n",
    "            y=hr.number_project,\n",
    "            hue=hr.left,\n",
    "            palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.scatterplot(x=hr.last_evaluation,\n",
    "            y=hr.number_project,\n",
    "            hue=hr.left,\n",
    "            palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(x=hr.average_montly_hours,\n",
    "            y=hr.last_evaluation,\n",
    "            hue=hr.left,\n",
    "            palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.scatterplot(x=hr.average_montly_hours,\n",
    "            y=hr.last_evaluation,\n",
    "            hue=hr.left,\n",
    "            palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(x=hr.satisfaction_level,\n",
    "            y=hr.last_evaluation,\n",
    "            hue=hr.left,\n",
    "            palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.scatterplot(x=hr.satisfaction_level,\n",
    "            y=hr.last_evaluation,\n",
    "            hue=hr.left,\n",
    "            palette = ('steelblue', 'crimson'))\n",
    "plt.tight_layout()\n",
    "\n",
    "salary_dict = {'low':0,'medium':1,'high':2}\n",
    "hr['salary_num'] = hr.salary.map(salary_dict)\n",
    "hr.drop('salary', inplace=True, axis=1)\n",
    "hr = hr.rename(index=str, columns={'salary_num':'salary'})\n",
    "hr.head()\n",
    "\n",
    "def numerical_features(df):\n",
    "    columns = df.columns\n",
    "    return df._get_numeric_data().columns\n",
    "\n",
    "def categorical_features(df):\n",
    "    numerical_columns = numerical_features(df)\n",
    "    return(list(set(df.columns) - set(numerical_columns)))\n",
    "\n",
    "def onehot_encode(df):\n",
    "    numericals = df.get(numerical_features(df))\n",
    "    new_df = numericals.copy()\n",
    "    for categorical_column in categorical_features(df):\n",
    "        new_df = pd.concat([new_df, \n",
    "                            pd.get_dummies(df[categorical_column], \n",
    "                                           prefix=categorical_column)], \n",
    "                           axis=1)\n",
    "    return new_df\n",
    "hr_encoded = onehot_encode(hr)\n",
    "hr_encoded.head()\n",
    "\n",
    "df_desc(hr_encoded)\n",
    "\n",
    "hr_encoded[['satisfaction_level',\n",
    "           'last_evaluation',\n",
    "           'average_montly_hours'\n",
    "           ]].hist(bins = 20, figsize = (15,10), color = 'steelblue')\n",
    "plt.tight_layout()\n",
    "\n",
    "hr_encoded[['satisfaction_level',\n",
    "           'last_evaluation',\n",
    "           'average_montly_hours'\n",
    "           ]].describe()\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "hr_scaled_part = scaler.fit_transform(hr_encoded[['satisfaction_level',\n",
    "                                                  'last_evaluation',\n",
    "                                                  'average_montly_hours']])\n",
    "hr_scaled_part = pd.DataFrame(hr_scaled_part, columns=list(['satisfaction_level',\n",
    "                                                  'last_evaluation',\n",
    "                                                  'average_montly_hours']))\n",
    "\n",
    "hr_scaled_part[['satisfaction_level',\n",
    "                'last_evaluation',\n",
    "                'average_montly_hours']].hist(bins = 20, figsize = (15,10), color = 'steelblue')\n",
    "plt.tight_layout()\n",
    "\n",
    "hr_scaled_part.describe()\n",
    "\n",
    "def feature_skewness(df):\n",
    "    numeric_dtypes = ['int16', 'int32', 'int64', \n",
    "                      'float16', 'float32', 'float64']\n",
    "    numeric_features = []\n",
    "    for i in df.columns:\n",
    "        if df[i].dtype in numeric_dtypes: \n",
    "            numeric_features.append(i)\n",
    "\n",
    "    feature_skew = df[numeric_features].apply(\n",
    "        lambda x: skew(x)).sort_values(ascending=False)\n",
    "    skews = pd.DataFrame({'skew':feature_skew})\n",
    "    return feature_skew, numeric_features\n",
    "def fix_skewness(df):\n",
    "    feature_skew, numeric_features = feature_skewness(df)\n",
    "    high_skew = feature_skew[feature_skew > 0.5]\n",
    "    skew_index = high_skew.index\n",
    "    \n",
    "    for i in skew_index:\n",
    "        df[i] = boxcox1p(df[i], boxcox_normmax(df[i]+1))\n",
    "\n",
    "    skew_features = df[numeric_features].apply(\n",
    "        lambda x: skew(x)).sort_values(ascending=False)\n",
    "    skews = pd.DataFrame({'skew':skew_features})\n",
    "    return df\n",
    "hr_skewed_part = fix_skewness(hr_scaled_part)\n",
    "hr_skewed_part.hist(bins = 20, figsize = (15,10), color = 'steelblue')\n",
    "plt.tight_layout()\n",
    "\n",
    "hr_skewed_part.describe()\n",
    "\n",
    "hr_simple = hr_encoded.copy()\n",
    "hr_simple.drop(['satisfaction_level',\n",
    "                'last_evaluation',\n",
    "                'average_montly_hours'], inplace=True, axis=1)\n",
    "\n",
    "hr_ready = pd.DataFrame()\n",
    "hr_simple.reset_index(drop=True, inplace=True)\n",
    "hr_skewed_part.reset_index(drop=True, inplace=True)\n",
    "\n",
    "hr_ready = pd.concat([hr_skewed_part,hr_simple], axis=1, sort=False, ignore_index=False)\n",
    "\n",
    "hr_ready.head()\n",
    "\n",
    "df_desc(hr_ready)\n",
    "hr_ready.describe()\n",
    "hr_ready.hist(bins = 20, figsize = (15,10), color = 'steelblue')\n",
    "plt.tight_layout()\n",
    "\n",
    "target = 'left'\n",
    "\n",
    "split_ratio = 0.3\n",
    "seed = 806\n",
    "\n",
    "def split_dataset(df, target, split_ratio=0.3, seed=806):\n",
    "    features = list(df)\n",
    "    features.remove(target)\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[[target]]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_ratio, random_state=seed)\n",
    "\n",
    "    return X, y, X_train, X_test, y_train, y_test\n",
    "\n",
    "X, y, X_train, X_test, y_train, y_test = split_dataset(hr_ready, target, split_ratio, seed)\n",
    "\n",
    "print('Features:',X.shape[0], 'items | ', X.shape[1],'columns')\n",
    "print('Target:',y.shape[0], 'items | ', y.shape[1],'columns')\n",
    "print('Features Train:',X_train.shape[0], 'items | ', X_train.shape[1],'columns')\n",
    "print('Features Test:',X_test.shape[0], 'items | ', X_test.shape[1],'columns')\n",
    "print('Target Train:',y_train.shape[0], 'items | ', y_train.shape[1],'columns')\n",
    "print('Target Test:',y_test.shape[0], 'items | ', y_test.shape[1],'columns')\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter = 300)\n",
    "def lr_run(model, X_train, y_train, X_test, y_test):\n",
    "    result = model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc_test = model.score(X_test, y_test)\n",
    "    coefficients = pd.concat([pd.DataFrame(X_train.columns, columns=['Feature']), pd.DataFrame(np.transpose(model.coef_), columns=['Coef.'])], axis = 1)\n",
    "    coefficients.loc[-1] = ['intercept.', model.intercept_[0]]\n",
    "    coefficients.index = coefficients.index + 1\n",
    "    coefficients = coefficients.sort_index()\n",
    "    \n",
    "    print('Accuracy on test: {:.3f}'.format(acc_test))\n",
    "    print()\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print()\n",
    "    print(coefficients)\n",
    "    \n",
    "lr_run(lr, X_train, y_train, X_test, y_test)\n",
    "\n",
    "def plot_roc(model, X_test, y_test):\n",
    "    logit_roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0.0, 1.05])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show();\n",
    "    \n",
    "plot_roc(lr, X_test, y_test)\n",
    "\n",
    "def cv_acc (model, X_train, y_train, n_splits, seed):\n",
    "    kfold = model_selection.KFold(n_splits=n_splits, random_state=seed)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(model, X_train, y_train.values.ravel(), cv=kfold, scoring=scoring)\n",
    "    print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))\n",
    "    print()\n",
    "    for i in range(len(results)):\n",
    "        print('Iteration', '{:>2}'.format(i+1), '| Accuracy: {:.2f}'.format(results[i]))\n",
    "        \n",
    "cv_acc(lr, X_train, y_train, 10, seed)\n",
    "\n",
    "hr_fe = hr_ready.copy()\n",
    "\n",
    "bins = [-1, 0.03, 0.29, 0.41, 0.69, 0.92, 1]\n",
    "labels=['(0.00, 0.11]','(0.11, 0.35]','(0.35, 0.46]','(0.46, 0.71]','(0.71, 0.92]','(0.92, 1.00]']\n",
    "hr_fe['satisfaction_level_bin'] = pd.cut(hr_fe.satisfaction_level, bins, labels=labels)\n",
    "hr_fe.satisfaction_level_bin.value_counts()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(x=hr_fe.satisfaction_level,\n",
    "              hue=hr_fe.satisfaction_level_bin,\n",
    "              palette = sns.color_palette(\"hls\", 6),\n",
    "              dodge = False)\n",
    "plt.tight_layout()\n",
    "\n",
    "hr_fe_1 = hr_fe.copy()\n",
    "hr_fe_1 = onehot_encode(hr_fe_1)\n",
    "hr_fe_1.drop('satisfaction_level', inplace=True, axis=1)\n",
    "\n",
    "X_fe_1, y_fe_1, X_fe_1_train, X_fe_1_test, y_fe_1_train, y_fe_1_test = split_dataset(hr_fe_1, target, split_ratio, seed)\n",
    "cv_acc(lr, X_fe_1_train, y_fe_1_train, 10, seed)\n",
    "print()\n",
    "lr_run(lr, X_fe_1_train, y_fe_1_train, X_fe_1_test, y_fe_1_test)\n",
    "\n",
    "bins = [-1, 0.14, 0.34, 0.64, 1]\n",
    "labels=['(0.00, 0.44]','(0.44, 0.57]','(0.57, 0.76]','(0.76, 1.00]']\n",
    "hr_fe['last_evaluation_bin'] = pd.cut(hr_fe.last_evaluation, bins, labels=labels)\n",
    "hr_fe_1['last_evaluation_bin'] = pd.cut(hr_fe_1.last_evaluation, bins, labels=labels)\n",
    "hr_fe_1.last_evaluation_bin.value_counts()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(x=hr_fe_1.last_evaluation,\n",
    "              hue=hr_fe_1.last_evaluation_bin,\n",
    "              palette = sns.color_palette(\"hls\", 6),\n",
    "              dodge = False)\n",
    "plt.tight_layout()\n",
    "\n",
    "hr_fe_2 = hr_fe_1.copy()\n",
    "hr_fe_2 = onehot_encode(hr_fe_2)\n",
    "hr_fe_2.drop('last_evaluation', inplace=True, axis=1)\n",
    "\n",
    "X_fe_2, y_fe_2, X_fe_2_train, X_fe_2_test, y_fe_2_train, y_fe_2_test = split_dataset(hr_fe_2, target, split_ratio, seed)\n",
    "cv_acc(lr, X_fe_2_train, y_fe_2_train, 10, seed)\n",
    "print()\n",
    "lr_run(lr, X_fe_2_train, y_fe_2_train, X_fe_2_test, y_fe_2_test)\n",
    "\n",
    "bins = [-1, 0.14, 0.165, 0.304, 0.565, 0.840, 0.897, 1]\n",
    "labels=['(0, 125]','(125, 131]','(131, 161]','(161, 216]','(216, 274]','(274, 287]','(287, 310]']\n",
    "hr_fe['average_montly_hours_bin'] = pd.cut(hr_fe.average_montly_hours, bins, labels=labels)\n",
    "hr_fe_2['average_montly_hours_bin'] = pd.cut(hr_fe_2.average_montly_hours, bins, labels=labels)\n",
    "hr_fe_2.average_montly_hours_bin.value_counts()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(x=hr_fe_2.average_montly_hours,\n",
    "              hue=hr_fe_2.average_montly_hours_bin,\n",
    "              palette = sns.color_palette(\"hls\", 7),\n",
    "              dodge = False)\n",
    "plt.tight_layout()\n",
    "\n",
    "hr_fe_3 = hr_fe_2.copy()\n",
    "hr_fe_3 = onehot_encode(hr_fe_3)\n",
    "hr_fe_3.drop('average_montly_hours', inplace=True, axis=1)\n",
    "X_fe_3, y_fe_3, X_fe_3_train, X_fe_3_test, y_fe_3_train, y_fe_3_test = split_dataset(hr_fe_3, target, split_ratio, seed)\n",
    "cv_acc(lr, X_fe_3_train, y_fe_3_train, 10, seed)\n",
    "print()\n",
    "lr_run(lr, X_fe_3_train, y_fe_3_train, X_fe_3_test, y_fe_3_test)\n",
    "\n",
    "categ = {2:'too low', 3:'normal', 4:'normal', 5:'normal', 6:'too high', 7:'extreme'}\n",
    "hr_fe['number_project_cat'] = hr_fe.number_project.map(categ)\n",
    "hr_fe_3['number_project_cat'] = hr_fe_3.number_project.map(categ)\n",
    "hr_fe_3.number_project_cat.value_counts()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(x=hr_fe_3.number_project,\n",
    "              hue=hr_fe_3.number_project_cat,\n",
    "              palette = sns.color_palette(\"hls\", 6),\n",
    "              dodge = False)\n",
    "plt.tight_layout()\n",
    "\n",
    "hr_fe_4 = hr_fe_3.copy()\n",
    "hr_fe_4 = onehot_encode(hr_fe_4)\n",
    "hr_fe_4.drop('number_project', inplace=True, axis=1)\n",
    "\n",
    "X_fe_4, y_fe_4, X_fe_4_train, X_fe_4_test, y_fe_4_train, y_fe_4_test = split_dataset(hr_fe_4, target, split_ratio, seed)\n",
    "cv_acc(lr, X_fe_4_train, y_fe_4_train, 10, seed)\n",
    "print()\n",
    "lr_run(lr, X_fe_4_train, y_fe_4_train, X_fe_4_test, y_fe_4_test)\n",
    "                    \n",
    "categ = {2:'low departure', 3:'high departure', 4:'high departure', 5:'very high departure', 6:'high departure', 7:'no departure', 8:'no departure', 10:'no departure'}\n",
    "hr_fe['time_spend_company_cat'] = hr_fe.time_spend_company.map(categ)\n",
    "hr_fe_4['time_spend_company_cat'] = hr_fe_4.time_spend_company.map(categ)\n",
    "hr_fe_4.time_spend_company_cat.value_counts()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(x=hr_fe_4.time_spend_company,\n",
    "              hue=hr_fe_4.time_spend_company_cat,\n",
    "              palette = sns.color_palette(\"hls\", 7),\n",
    "              dodge = False)\n",
    "plt.tight_layout()\n",
    "\n",
    "hr_fe_5 = hr_fe_4.copy()\n",
    "hr_fe_5 = onehot_encode(hr_fe_5)\n",
    "hr_fe_5.drop('time_spend_company', inplace=True, axis=1)\n",
    "\n",
    "X_fe_5, y_fe_5, X_fe_5_train, X_fe_5_test, y_fe_5_train, y_fe_5_test = split_dataset(hr_fe_5, target, split_ratio, seed)\n",
    "cv_acc(lr, X_fe_5_train, y_fe_5_train, 10, seed)\n",
    "print()\n",
    "lr_run(lr, X_fe_5_train, y_fe_5_train, X_fe_5_test, y_fe_5_test)\n",
    "\n",
    "def workload_cluster(row):\n",
    "    if (row['average_montly_hours_bin'] == '(0, 125]'):\n",
    "        return 'very low'\n",
    "    if (row['number_project'] <= 2) and (row['average_montly_hours_bin'] in ['(125, 131]','(131, 161]']):\n",
    "        return 'low'\n",
    "    if (row['number_project'] >= 4) and (row['average_montly_hours_bin'] in ['(216, 274]','(274, 287]']):\n",
    "        return 'high'\n",
    "    if (row['average_montly_hours_bin'] in ['(287, 310]']):\n",
    "        return 'extreme'\n",
    "    return 'normal'\n",
    "\n",
    "hr_fe['workload'] = hr_fe.apply(lambda row: workload_cluster(row), axis=1)\n",
    "hr_fe.workload.value_counts()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.scatterplot(x=hr_fe.average_montly_hours,\n",
    "                y=hr_fe.number_project,\n",
    "                hue=hr_fe.workload,\n",
    "                palette = sns.color_palette(\"hls\", 5))\n",
    "plt.tight_layout()\n",
    "\n",
    "hr_fe_6 = hr_fe.copy()\n",
    "hr_fe_6 = onehot_encode(hr_fe_6)\n",
    "hr_fe_6.drop('satisfaction_level', inplace=True, axis=1)\n",
    "hr_fe_6.drop('last_evaluation', inplace=True, axis=1)\n",
    "hr_fe_6.drop('average_montly_hours', inplace=True, axis=1)\n",
    "hr_fe_6.drop('number_project', inplace=True, axis=1)\n",
    "hr_fe_6.drop('time_spend_company', inplace=True, axis=1)\n",
    "\n",
    "X_fe_6, y_fe_6, X_fe_6_train, X_fe_6_test, y_fe_6_train, y_fe_6_test = split_dataset(hr_fe_6, target, split_ratio, seed)\n",
    "cv_acc(lr, X_fe_6_train, y_fe_6_train, 10, seed)\n",
    "print()\n",
    "lr_run(lr, X_fe_6_train, y_fe_6_train, X_fe_6_test, y_fe_6_test)\n",
    "\n",
    "def project_performance_cluster(row):\n",
    "    if (row['last_evaluation_bin'] == '(0.00, 0.44]'):\n",
    "        return 'very low'\n",
    "    if (row['number_project'] <= 2) and (row['last_evaluation_bin'] in ['(0.44, 0.57]']):\n",
    "        return 'low'\n",
    "    if (row['number_project'] >= 4) and (row['last_evaluation_bin'] in ['(0.76, 1.00]']):\n",
    "        return 'high'\n",
    "    return 'normal'\n",
    "\n",
    "hr_fe['project_performance'] = hr_fe.apply(lambda row: project_performance_cluster(row), axis=1)\n",
    "hr_fe.project_performance.value_counts()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.scatterplot(x=hr_fe.last_evaluation,\n",
    "                y=hr_fe.number_project,\n",
    "                hue=hr_fe.project_performance,\n",
    "                palette = sns.color_palette(\"hls\", 4))\n",
    "plt.tight_layout()\n",
    "\n",
    "hr_fe_7 = hr_fe.copy()\n",
    "hr_fe_7 = onehot_encode(hr_fe_7)\n",
    "hr_fe_7.drop('satisfaction_level', inplace=True, axis=1)\n",
    "hr_fe_7.drop('last_evaluation', inplace=True, axis=1)\n",
    "hr_fe_7.drop('average_montly_hours', inplace=True, axis=1)\n",
    "hr_fe_7.drop('number_project', inplace=True, axis=1)\n",
    "hr_fe_7.drop('time_spend_company', inplace=True, axis=1)\n",
    "\n",
    "X_fe_7, y_fe_7, X_fe_7_train, X_fe_7_test, y_fe_7_train, y_fe_7_test = split_dataset(hr_fe_7, target, split_ratio, seed)\n",
    "cv_acc(lr, X_fe_7_train, y_fe_7_train, 10, seed)\n",
    "print()\n",
    "lr_run(lr, X_fe_7_train, y_fe_7_train, X_fe_7_test, y_fe_7_test)\n",
    "\n",
    "def efficiency_cluster(row):\n",
    "    if (row['last_evaluation_bin'] == '(0.00, 0.44]'):\n",
    "        return 'very low'\n",
    "    if (row['average_montly_hours_bin'] in ['(0, 125]']):\n",
    "        return 'very low'\n",
    "    if (row['last_evaluation_bin'] in ['(0.44, 0.57]']) and (row['average_montly_hours_bin'] in ['(125, 131]', '(131, 161]']):\n",
    "        return 'low'\n",
    "    if (row['last_evaluation_bin'] in ['(0.76, 1.00]']) and (row['average_montly_hours_bin'] in ['(216, 274]', '(274, 287]','(287, 310]']):\n",
    "        return 'high'\n",
    "    return 'normal'\n",
    "\n",
    "hr_fe['efficiency'] = hr_fe.apply(lambda row: efficiency_cluster(row), axis=1)\n",
    "hr_fe.efficiency.value_counts()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.scatterplot(x=hr_fe.average_montly_hours,\n",
    "                y=hr_fe.last_evaluation,\n",
    "                hue=hr_fe.efficiency,\n",
    "                palette = sns.color_palette(\"hls\", 4))\n",
    "plt.tight_layout()\n",
    "\n",
    "hr_fe_8 = hr_fe.copy()\n",
    "hr_fe_8 = onehot_encode(hr_fe_8)\n",
    "hr_fe_8.drop('satisfaction_level', inplace=True, axis=1)\n",
    "hr_fe_8.drop('last_evaluation', inplace=True, axis=1)\n",
    "hr_fe_8.drop('average_montly_hours', inplace=True, axis=1)\n",
    "hr_fe_8.drop('number_project', inplace=True, axis=1)\n",
    "hr_fe_8.drop('time_spend_company', inplace=True, axis=1)\n",
    "\n",
    "X_fe_8, y_fe_8, X_fe_8_train, X_fe_8_test, y_fe_8_train, y_fe_8_test = split_dataset(hr_fe_8, target, split_ratio, seed)\n",
    "cv_acc(lr, X_fe_8_train, y_fe_8_train, 10, seed)\n",
    "print()\n",
    "lr_run(lr, X_fe_8_train, y_fe_8_train, X_fe_8_test, y_fe_8_test)\n",
    "\n",
    "def attitude_cluster(row):\n",
    "    if (row['last_evaluation_bin'] == '(0.00, 0.44]'):\n",
    "        return 'low performance'\n",
    "    if (row['satisfaction_level_bin'] in ['(0.92, 1.00]']):\n",
    "        return 'very happy'\n",
    "    if (row['last_evaluation_bin'] in ['(0.76, 1.00]']) and (row['satisfaction_level_bin'] in ['(0.71, 0.92]']):\n",
    "        return 'happy and high performance'\n",
    "    if (row['last_evaluation_bin'] in ['(0.44, 0.57]']) and (row['satisfaction_level_bin'] in ['(0.35, 0.46]']):\n",
    "        return 'unhappy and low performance'\n",
    "    if (row['satisfaction_level_bin'] in ['(0.00, 0.11]']):\n",
    "        return 'very unhappy'\n",
    "    if (row['satisfaction_level_bin'] in ['(0.11, 0.35]','(0.35, 0.46]']):\n",
    "        return 'unhappy'\n",
    "    return 'normal'\n",
    "\n",
    "hr_fe['attitude'] = hr_fe.apply(lambda row: attitude_cluster(row), axis=1)\n",
    "hr_fe.attitude.value_counts()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.scatterplot(x=hr_fe.satisfaction_level,\n",
    "                y=hr_fe.last_evaluation,\n",
    "                hue=hr_fe.attitude,\n",
    "                palette = sns.color_palette(\"hls\", 7))\n",
    "plt.tight_layout()\n",
    "\n",
    "hr_fe_9 = hr_fe.copy()\n",
    "hr_fe_9 = onehot_encode(hr_fe_9)\n",
    "hr_fe_9.drop('satisfaction_level', inplace=True, axis=1)\n",
    "hr_fe_9.drop('last_evaluation', inplace=True, axis=1)\n",
    "hr_fe_9.drop('average_montly_hours', inplace=True, axis=1)\n",
    "hr_fe_9.drop('number_project', inplace=True, axis=1)\n",
    "hr_fe_9.drop('time_spend_company', inplace=True, axis=1)\n",
    "\n",
    "X_fe_9, y_fe_9, X_fe_9_train, X_fe_9_test, y_fe_9_train, y_fe_9_test = split_dataset(hr_fe_9, target, split_ratio, seed)\n",
    "cv_acc(lr, X_fe_9_train, y_fe_9_train, 10, seed)\n",
    "print()\n",
    "lr_run(lr, X_fe_9_train, y_fe_9_train, X_fe_9_test, y_fe_9_test)\n",
    "\n",
    "hr_fe_encoded = onehot_encode(hr_fe)\n",
    "hr_fe_encoded.drop('satisfaction_level', inplace=True, axis=1)\n",
    "hr_fe_encoded.drop('last_evaluation', inplace=True, axis=1)\n",
    "hr_fe_encoded.drop('average_montly_hours', inplace=True, axis=1)\n",
    "hr_fe_encoded.drop('number_project', inplace=True, axis=1)\n",
    "hr_fe_encoded.drop('time_spend_company', inplace=True, axis=1)\n",
    "df_desc(hr_fe_encoded)\n",
    "\n",
    "X_fe_encoded, y_fe_encoded, X_fe_encoded_train, X_fe_encoded_test, y_fe_encoded_train, y_fe_encoded_test = split_dataset(hr_fe_encoded, target, split_ratio, seed)\n",
    "cv_acc(lr, X_fe_encoded_train, y_fe_encoded_train, 10, seed)\n",
    "print()\n",
    "lr_run(lr, X_fe_encoded_train, y_fe_encoded_train, X_fe_encoded_test, y_fe_encoded_test)\n",
    "\n",
    "plot_roc(lr, X_fe_encoded_test, y_fe_encoded_test)\n",
    "\n",
    "accuracies = pd.DataFrame(columns=['features','accuracy', 'cols'])\n",
    "print('Iterations:')\n",
    "\n",
    "for i in range(1, len(X_fe_encoded.columns)+1):\n",
    "    logreg = LogisticRegression(solver='lbfgs', max_iter=250)\n",
    "    rfe = RFE(logreg, i)\n",
    "    rfe = rfe.fit(X_fe_encoded, y_fe_encoded.values.ravel())\n",
    "    \n",
    "    cols_rfe = list(X_fe_encoded.loc[:, rfe.support_])\n",
    "    X_rfe_sel = X_fe_encoded_train[cols_rfe]\n",
    "    X_rfe_test_sel = X_fe_encoded_test[cols_rfe]\n",
    "\n",
    "    result = logreg.fit(X_rfe_sel, y_fe_encoded_train.values.ravel())\n",
    "    acc_test = logreg.score(X_rfe_test_sel, y_fe_encoded_test)\n",
    "    \n",
    "    accuracies.loc[i] = [i, acc_test, cols_rfe]\n",
    "    print(i, end='   ')\n",
    "    \n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = accuracies['features'],\n",
    "             y = accuracies['accuracy'],\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()\n",
    "\n",
    "accuracies.nlargest(10, 'accuracy')\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "features_rfe = list(hr_fe_encoded)\n",
    "features_rfe.remove(target)\n",
    "\n",
    "X_rfe = hr_fe_encoded.loc[:, features_rfe]\n",
    "y_rfe = hr_fe_encoded.loc[:, target]\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=250)\n",
    "rfe = RFE(logreg, accuracies.nlargest(1,'accuracy').features.values.ravel()[0])\n",
    "rfe = rfe.fit(X_rfe, y_rfe)\n",
    "\n",
    "print(sum(rfe.support_),'selected features:')\n",
    "for i in list(X_rfe.loc[:, rfe.support_]):\n",
    "    print(i)\n",
    "    \n",
    "cols = list(X_rfe.loc[:, rfe.support_]) + [target]\n",
    "hr_sel = hr_fe_encoded[cols]\n",
    "X_sel, y_sel, X_sel_train, X_sel_test, y_sel_train, y_sel_test = split_dataset(hr_sel, target, split_ratio, seed)\n",
    "cv_acc(lr, X_sel_train, y_sel_train, 10, seed)\n",
    "print()\n",
    "lr_run(lr, X_sel_train, y_sel_train, X_sel_test, y_sel_test)\n",
    "\n",
    "plot_roc(lr, X_sel_test, y_sel_test)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "os = SMOTE(random_state=0)\n",
    "X_smote, y_smote, X_smote_train, X_smote_test, y_smote_train, y_smote_test = split_dataset(hr_fe_encoded, target, split_ratio, seed)\n",
    "columns = X_smote_train.columns\n",
    "\n",
    "os_data_X,os_data_y = os.fit_sample(X_smote_train, y_smote_train.values.ravel())\n",
    "os_data_X = pd.DataFrame(data=os_data_X, columns=columns)\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['left'])\n",
    "\n",
    "print(\"Length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of 'stayed' in oversampled data\",len(os_data_y[os_data_y['left']==0]))\n",
    "print(\"Number of 'left'\",len(os_data_y[os_data_y['left']==1]))\n",
    "print(\"Proportion of 'stayed' data in oversampled data is \",len(os_data_y[os_data_y['left']==0])/len(os_data_X))\n",
    "print(\"Proportion of 'left' data in oversampled data is \",len(os_data_y[os_data_y['left']==1])/len(os_data_X))\n",
    "\n",
    "cv_acc(lr, os_data_X, os_data_y, 10, seed)\n",
    "print()\n",
    "lr_run(lr, os_data_X, os_data_y, X_smote_test, y_smote_test)\n",
    "\n",
    "accuracies_smote = pd.DataFrame(columns=['features','accuracy', 'cols'])\n",
    "print('Iterations:')\n",
    "\n",
    "for i in range(1, len(os_data_X.columns)+1):\n",
    "    logreg = LogisticRegression(solver='lbfgs', max_iter=250)\n",
    "    rfe_smote = RFE(logreg, i)\n",
    "    rfe_smote = rfe_smote.fit(os_data_X, os_data_y.values.ravel())\n",
    "    \n",
    "    cols_rfe_smote = list(os_data_X.loc[:, rfe_smote.support_])\n",
    "    os_data_X_sel = os_data_X[cols_rfe_smote]\n",
    "    X_smote_test_sel = X_smote_test[cols_rfe_smote]\n",
    "\n",
    "    result = logreg.fit(os_data_X_sel, os_data_y.values.ravel())\n",
    "    acc_test = logreg.score(X_smote_test_sel, y_smote_test)\n",
    "    \n",
    "    accuracies_smote.loc[i] = [i, acc_test, cols_rfe_smote]\n",
    "    print(i, end='   ')\n",
    "    \n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x = accuracies_smote['features'],\n",
    "             y = accuracies_smote['accuracy'],\n",
    "             color = 'steelblue')\n",
    "plt.tight_layout()\n",
    "\n",
    "accuracies_smote.nlargest(10, 'accuracy')\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=250)\n",
    "rfe_smote = RFE(logreg, accuracies_smote.nlargest(1,'accuracy').features.values.ravel()[0])\n",
    "rfe_smote = rfe_smote.fit(os_data_X, os_data_y.values.ravel())\n",
    "\n",
    "print(sum(rfe_smote.support_),'selected features:')\n",
    "for i in list(os_data_X.loc[:, rfe_smote.support_]):\n",
    "    print(i)\n",
    "    \n",
    "cols_smote = list(os_data_X.loc[:, rfe_smote.support_])\n",
    "os_data_X_sel = os_data_X[cols_smote]\n",
    "X_smote_test_sel = X_smote_test[cols_smote]\n",
    "\n",
    "cv_acc(lr, os_data_X_sel, os_data_y, 10, seed)\n",
    "print()\n",
    "lr_run(lr, os_data_X_sel, os_data_y, X_smote_test_sel, y_smote_test)\n",
    "\n",
    "list_features = pd.DataFrame({'Initial':sorted(list(accuracies.loc[accuracies.features == 14]['cols'])[0]),\n",
    "                          'SMOTE':sorted(list(accuracies_smote.loc[accuracies_smote.features == 14]['cols'])[0])})\n",
    "list_features\n",
    "\n",
    "cols_1 = cols.copy()\n",
    "cols_1.remove('left')\n",
    "print(cols_1)\n",
    "os_data_X_sel_1 = os_data_X[cols_1]\n",
    "X_smote_test_sel_1 = X_smote_test[cols_1]\n",
    "\n",
    "cv_acc(lr, os_data_X_sel_1, os_data_y, 10, seed)\n",
    "print()\n",
    "lr_run(lr, os_data_X_sel_1, os_data_y, X_smote_test_sel_1, y_smote_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
