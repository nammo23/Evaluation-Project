{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20641a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joypy\n",
    "!pip install bubbly\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import joypy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import plotting\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "import plotly\n",
    "import plotly.offline as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "init_notebook_mode(connected = True)\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from bubbly.bubbly import bubbleplot\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "import sklearn\n",
    "import imblearn\n",
    "import shap \n",
    "import eli5\n",
    "\n",
    "data = pd.read_csv('../input/insurance_claims.csv')\n",
    "\n",
    "data.head()\n",
    "data.sample(5)\n",
    "data.shape\n",
    "data.describe()\n",
    "data.info()\n",
    "data = data.replace('?',np.NaN)\n",
    "data.isnull().any()\n",
    "data['collision_type'].fillna(data['collision_type'].mode()[0], inplace = True)\n",
    "data['property_damage'].fillna('NO', inplace = True)\n",
    "data['police_report_available'].fillna('NO', inplace = True)\n",
    "data.isnull().any().any()\n",
    "\n",
    "fraud = data['fraud_reported'].value_counts()\n",
    "\n",
    "label_fraud = fraud.index\n",
    "size_fraud = fraud.values\n",
    "\n",
    "colors = ['silver', 'gold']\n",
    "trace = go.Pie(\n",
    "         labels = label_fraud, values = size_fraud, marker = dict(colors = colors), name = 'Frauds', hole = 0.3)\n",
    "df = [trace]\n",
    "layout = go.Layout(\n",
    "           title = 'Distribution of Frauds')\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "py.iplot(fig)\n",
    "\n",
    "fig, axes = joypy.joyplot(data,\n",
    "                         column = ['incident_hour_of_the_day','number_of_vehicles_involved', 'witnesses'],\n",
    "                         by = 'incident_city',\n",
    "                         ylim = 'own',\n",
    "                         figsize = (20, 10),\n",
    "                         alpha = 0.5, \n",
    "                         legend = True)\n",
    "\n",
    "plt.title('Incident hour, No. of vehicles, witnesses vs Incident City', fontsize = 20)\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "sns.stripplot(data['property_damage'], data['property_claim'], palette = 'bone')\n",
    "plt.title('Incident Type vs Vehicle Claim', fontsize = 20)\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "sns.boxenplot(data['incident_type'], data['vehicle_claim'], palette = 'pink')\n",
    "plt.title('Incident Type vs Vehicle Claim', fontsize = 20)\n",
    "plt.show()\n",
    "\n",
    "incident = pd.crosstab(data['incident_city'], data['incident_type'])\n",
    "colors = plt.cm.Blues(np.linspace(0, 1, 5))\n",
    "incident.div(incident.sum(1).astype(float), axis = 0).plot(kind = 'bar',\n",
    "                                                           stacked = False,\n",
    "                                                           figsize = (15, 7),\n",
    "                                                           color = colors)\n",
    "plt.title('Incident Type vs Collision Type', fontsize = 20)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "incident = pd.crosstab(data['incident_type'], data['incident_severity'])\n",
    "colors = plt.cm.summer(np.linspace(0, 1, 5))\n",
    "incident.div(incident.sum(1).astype(float), axis = 0).plot(kind = 'bar',\n",
    "                                                           stacked = False,\n",
    "                                                           figsize = (15, 7),\n",
    "                                                           color = colors)\n",
    "plt.title('Incident Type vs Collision Type', fontsize = 20)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "incident = pd.crosstab(data['incident_type'], data['collision_type'])\n",
    "colors = plt.cm.inferno(np.linspace(0, 1, 5))\n",
    "incident.div(incident.sum(1).astype(float), axis = 0).plot(kind = 'bar',\n",
    "                                                           stacked = True,\n",
    "                                                           figsize = (15, 7),\n",
    "                                                           color = colors)\n",
    "plt.title('Incident Type vs Collision Type', fontsize = 20)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "sns.countplot(data['insured_occupation'], palette = 'PuRd')\n",
    "plt.title('Different Types of Occupation of Insured Customers', fontsize = 20)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "sns.countplot(data['insured_hobbies'], palette = 'cool')\n",
    "plt.title('Different Types of Hobbies of Insured Customers', fontsize = 20)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show() \n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "sns.countplot(data['incident_type'], palette = 'spring')\n",
    "plt.title('Different Types of Incidents', fontsize = 20)\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "sns.swarmplot(data['policy_state'], data['total_claim_amount'], palette = 'copper')\n",
    "plt.title('Policy State vs Total Claim Amount', fontsize = 20)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 10), dpi= 80)\n",
    "\n",
    "parallel_coordinates(data[['total_claim_amount','injury_claim', 'property_claim','vehicle_claim','fraud_reported']],\n",
    "                     'fraud_reported',  colormap = 'copper')\n",
    "plt.gca().spines[\"top\"].set_alpha(0)\n",
    "plt.gca().spines[\"bottom\"].set_alpha(.3)\n",
    "plt.gca().spines[\"right\"].set_alpha(0)\n",
    "plt.gca().spines[\"left\"].set_alpha(.3)\n",
    "\n",
    "plt.title('DC', fontsize = 20)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.suptitle('total claim, Injury claim, Property claim, vehicle claim vs Fraud Reported', fontsize = 20)\n",
    "plt.show()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "figure = bubbleplot(dataset = data, x_column = 'policy_annual_premium', y_column = 'total_claim_amount', \n",
    "    bubble_column = 'insured_sex', time_column = 'auto_year', size_column = 'months_as_customer', color_column = 'insured_sex', \n",
    "    x_title = \"Annual Policy Premium\", y_title = \"Total Claim Amount\", title = 'Annual Premium vs Total Claim Amount vs Months as Customer',\n",
    "    x_logscale = False, scale_bubble = 3, height = 650)\n",
    "\n",
    "py.iplot(figure, config={'scrollzoom': True})\n",
    "\n",
    "trace = go.Histogram(\n",
    "          x = data['insured_education_level'],\n",
    "          name = 'Marvel',\n",
    "          opacity = 0.75,\n",
    "          marker = dict(\n",
    "                 color = 'rgb(195, 195, 145, 0.5)'\n",
    "          )\n",
    ")\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Education Level of the Customers')\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "py.iplot(fig)\n",
    "\n",
    "trace = go.Histogram(\n",
    "          x = data['insured_occupation'],\n",
    "          name = 'Marvel',\n",
    "          opacity = 0.75,\n",
    "          marker = dict(\n",
    "                 color = 'rgb(15, 255, 185, 0.5)'\n",
    "          )\n",
    ")\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Occupation of the Customers')\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "py.iplot(fig)\n",
    "sex = data['insured_sex'].value_counts()\n",
    "rel = data['insured_relationship'].value_counts()\n",
    "\n",
    "label_sex = sex.index\n",
    "size_sex = sex.values\n",
    "\n",
    "label_rel = rel.index\n",
    "size_rel = rel.values\n",
    "\n",
    "colors = ['aqua', 'gold']\n",
    "trace = go.Pie(\n",
    "         labels = label_sex, values = size_sex, marker = dict(colors = colors), name = 'Gender', hole = 0.3)\n",
    "\n",
    "colors2 = ['pink', 'lightblue','lightgreen','grey','red']\n",
    "trace2 = go.Pie(labels = label_rel, values = size_rel, marker = dict(colors = colors2), name = 'Relationship',\n",
    "                hole = 0.3)\n",
    "\n",
    "df = [trace]\n",
    "df2 = [trace2]\n",
    "layout1 = go.Layout(\n",
    "           title = 'Gender of the Customers')\n",
    "layout2 = go.Layout(\n",
    "           title = 'Relationship')\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout1)\n",
    "fig2 = go.Figure(data = df2, layout = layout2)\n",
    "py.iplot(fig)\n",
    "py.iplot(fig2)\n",
    "trace = go.Violin(\n",
    "          x = data['insured_sex'],\n",
    "          y = data['insured_zip'],\n",
    "          name = 'Gender vs Insured Zip',\n",
    "          opacity = 0.75,\n",
    "          marker = dict(\n",
    "                 color = 'rgb(215, 5, 185, 0.5)'\n",
    "          )\n",
    ")\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Gender vs Insured Zip')\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "py.iplot(fig)\n",
    "trace = go.Box(\n",
    "          x = data['auto_make'],\n",
    "          y = data['vehicle_claim'],\n",
    "          opacity = 0.7,\n",
    "          marker = dict(\n",
    "                 color = 'rgb(215, 195, 5, 0.5)'\n",
    "                     )\n",
    ")\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Automobile Company vs Vehicle Claim')\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "py.iplot(fig)\n",
    "trace = go.Histogram(\n",
    "          x = data['policy_annual_premium'],\n",
    "          \n",
    "          #fill = 'tozeroy',\n",
    "          marker = dict(\n",
    "                 color = 'rgb(100, 75, 25, 0.5)'\n",
    "          )\n",
    ")\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Distribution of Annual Policy among the Customers',\n",
    "    scene = dict(\n",
    "            xaxis = dict(title  = 'Age'),\n",
    "            yaxis = dict(title  = 'Count')\n",
    "        ))\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "py.iplot(fig)\n",
    "trace = go.Histogram(\n",
    "          x = data['age'],\n",
    "    marker = dict(\n",
    "                 color = 'rgb(215, 245, 5, 0.5)'\n",
    "          )\n",
    ")\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Distribution of Age among the Customers',\n",
    "    scene = dict(\n",
    "            xaxis = dict(title  = 'Age'),\n",
    "            yaxis = dict(title  = 'Count')\n",
    "        ))\n",
    "\n",
    "fig = go.Figure(data = df, layout = layout)\n",
    "py.iplot(fig)\n",
    "trace = go.Scatter3d(\n",
    "    x = data['age'],\n",
    "    y = data['property_claim'],\n",
    "    z = data['vehicle_claim'],\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "         size = 10,\n",
    "         color = data['age']\n",
    "    )\n",
    ")\n",
    "\n",
    "df = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Cholestrol vs Heart Rate vs Age',\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0  \n",
    "    ),\n",
    "    scene = dict(\n",
    "         xaxis = dict(title  = 'Age'),\n",
    "            yaxis = dict(title  = 'Property_claim'),\n",
    "            zaxis = dict(title  = 'Vehicle_claim')\n",
    "        )\n",
    "    \n",
    ")\n",
    "fig = go.Figure(data = df, layout=layout)\n",
    "py.iplot(fig)\n",
    "data['policy_bind_date'] = pd.to_datetime(data['policy_bind_date'], errors = 'coerce')\n",
    "data['fraud_reported'] = data['fraud_reported'].replace(('Y','N'),(0,1))\n",
    "data[['auto_model','fraud_reported']].groupby(['auto_model'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['auto_make'] = data['auto_make'].replace(('3 Series','RSX','Malibu','Wrangler','Pathfinder','Ultima','Camry',\n",
    "                'Corolla','CRV','Legacy','Neon','95','TL','93','MDX','Accord','Grand Cherokee','Escape','E4000',\n",
    "            'A3','Highlander','Passat','92x','Jetta','Fusion','Forrestor','Maxima','Impreza','X5','RAM','M5','A5',\n",
    "                'Civic','F150','Tahaoe','C300','ML350','Silverado','X6'),\n",
    "                (0.95,0.91, 0.90,0.88,0.87,0.86,0.855,0.85,0.85,0.84,0.83,0.81,0.80,0.80,0.78,0.77,0.76,0.75,0.74,\n",
    "                 0.73,0.72,0.72,0.71,0.71,0.71,0.71,0.70,0.70,0.69,0.67,0.66,0.65,0.64,0.63,0.62,0.61,0.60,0.59,0.56))\n",
    "data[['auto_make','fraud_reported']].groupby(['auto_make'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['auto_make'] = data['auto_make'].replace(('Jeep','Nissan','Toyota','Accura','Saab','Suburu',\n",
    "                                'Dodge','Honda','Chevrolet','BMW','Volkswagen','Audi','Ford','Mercedes'),\n",
    "                                              (0.84,0.82,0.81,0.80,0.77,0.76,0.75,0.74,0.73,0.72,0.71,0.69,0.69,0.66))\n",
    "data[['police_report_available','fraud_reported']].groupby(['police_report_available'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['police_report_available'] = data['police_report_available'].replace(('NO','YES'),(0.77,0.74))\n",
    "data[['property_damage','fraud_reported']].groupby(['property_damage'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['property_damage'] = data['property_damage'].replace(('NO','YES'),(0.76,0.74))\n",
    "data[['incident_city','fraud_reported']].groupby(['incident_city'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['incident_city'] = data['incident_city'].replace(('Northbrook','Riverwood','Northbend','Springfield',\n",
    "                                    'Hillsdale','Columbus','Arlington'),(0.78,0.77,0.76,0.75,0.74,0.73,0.71))\n",
    "data[['incident_state','fraud_reported']].groupby(['incident_state'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['incident_state'] = data['incident_state'].replace(('WV','NY','VA','PA','SC','NC','OH'),\n",
    "                                                        (0.82,0.77,0.76,0.73,0.70,0.69,0.56))\n",
    "data[['authorities_contacted','fraud_reported']].groupby(['authorities_contacted'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['authorities_contacted'] = data['authorities_contacted'].replace(('None','Police','Fire','Ambulance','Other'),\n",
    "                                                                      (0.94,0.79,0.73,0.70,0.68))\n",
    "data[['incident_severity','fraud_reported']].groupby(['incident_severity'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['incident_severity'] = data['incident_severity'].replace(('Trivial Damage','Minor Damage','Total Loss',\n",
    "                                                              'Major Damage'),(0.94,0.89,0.87,0.39))\n",
    "data[['collision_type','fraud_reported']].groupby(['collision_type'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['collision_type'] = data['collision_type'].replace(('Rear Collision', 'Side Collision', 'Front Collision'),\n",
    "                                                        (0.78,0.74,0.72))\n",
    "data[['incident_type','fraud_reported']].groupby(['incident_type'],\n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['incident_type'] = data['incident_type'].replace(('Vehicle Theft','Parked Car','Multi-vehicle Collision',\n",
    "                                'Single Vehicle Collision'),(0.91, 0.90, 0.72,0.70))\n",
    "data['incident_date'] = pd.to_datetime(data['incident_date'], errors = 'coerce')\n",
    "\n",
    "data['incident_month'] = data['incident_date'].dt.month\n",
    "data['incident_day'] = data['incident_date'].dt.day\n",
    "data[['insured_relationship','fraud_reported']].groupby(['insured_relationship'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['insured_relationship'] = data['insured_relationship'].replace(('husband','own-child','unmarried',\n",
    "                                        'not-in-family','wife','other-relative'),(0.79,0.78,0.75,0.74,0.72,0.70))\n",
    "data[['insured_hobbies','fraud_reported']].groupby(['insured_hobbies'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['insured_hobbies'] = data['insured_hobbies'].replace(('camping', 'kayaking', 'golf','dancing',\n",
    "        'bungie-jumping','movies', 'basketball','exercise','sleeping','video-games','skydiving','paintball',\n",
    "            'hiking','base-jumping','reading','polo','board-games','yachting', 'cross-fit','chess'),(0.91, 0.90,\n",
    "                0.89, 0.88,0.84,0.83,0.82,0.81,0.805,0.80,0.78,0.77,0.76,0.73,0.73,0.72,0.70,0.69,0.25,0.17))\n",
    "data[['insured_occupation','fraud_reported']].groupby(['insured_occupation'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['insured_occupation'] = data['insured_occupation'].replace(('other-service','priv-house-serv',\n",
    "                        'adm-clerical','handlers-cleaners','prof-specialty','protective-serv',\n",
    "                'machine-op-inspct','armed-forces','sales','tech-support','transport-moving','craft-repair',\n",
    "                    'farming-fishing','exec-managerial'),(0.84, 0.84,0.83, 0.79,0.78,0.77,0.76,0.75,0.72,0.71,\n",
    "                                                          0.705,0.70,0.69,0.63))\n",
    "data[['insured_education_level','fraud_reported']].groupby(['insured_education_level'], \n",
    "                as_index = False).mean().sort_values(by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['insured_education_level'] = data['insured_education_level'].replace(('Masters', 'High School','Associate',\n",
    "                                        'JD','College', 'MD','PhD'),(0.78,0.77,0.76,0.74,0.73,0.72,0.71))\n",
    "data[['insured_sex','fraud_reported']].groupby(['insured_sex'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['insured_sex'] = data['insured_sex'].replace(('FEMALE','MALE'),(0.76,0.73))\n",
    "data[['policy_csl','fraud_reported']].groupby(['policy_csl'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['policy_csl'] = data['policy_csl'].replace(('500/1000','100/300','250/500'),(0.78,0.74,0.73))\n",
    "data[['policy_state','fraud_reported']].groupby(['policy_state'], as_index = False).mean().sort_values(\n",
    "    by = 'fraud_reported', ascending = False)\n",
    "\n",
    "data['policy_state'] = data['policy_state'].replace(('IL','IN','OH'),(0.77,0.745,0.74))\n",
    "data = data.drop(['policy_number','policy_bind_date', 'incident_date','incident_location','auto_model'], axis = 1)\n",
    "\n",
    "data.columns\n",
    "\n",
    "x = data.drop(['fraud_reported'], axis = 1)\n",
    "y = data['fraud_reported']\n",
    "\n",
    "print(\"Shape of x :\", x.shape)\n",
    "print(\"Shape of y :\", y.shape)\n",
    "\n",
    "x = data.drop(['fraud_reported'], axis = 1)\n",
    "y = data['fraud_reported']\n",
    "\n",
    "print(\"Shape of x :\", x.shape)\n",
    "print(\"Shape of y :\", y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"Shape of x_train :\", x_train.shape)\n",
    "print(\"Shape of x_test :\", x_test.shape)\n",
    "print(\"Shape of y_train :\", y_train.shape)\n",
    "print(\"Shape of y_test :\", y_test.shape)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "sns.heatmap(x_train.corr(), cmap = 'copper')\n",
    "plt.title('Heat Map for Correlations', fontsize = 20)\n",
    "plt.show()\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "                 \n",
    "\n",
    "model = BalancedRandomForestClassifier(n_estimators = 100, random_state = 0)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred_rf = model.predict(x_test)\n",
    "\n",
    "print(\"Training Accuracy: \", model.score(x_train, y_train))\n",
    "print('Testing Accuarcy: ', model.score(x_test, y_test))\n",
    "cr = classification_report(y_test,  y_pred_rf)\n",
    "print(cr)\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm, annot = True, cmap = 'spring')\n",
    "plt.show()\n",
    "\n",
    "from imblearn.ensemble import EasyEnsembleClassifier \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "                 \n",
    "model1 = EasyEnsembleClassifier(n_estimators = 100, random_state = 0)\n",
    "\n",
    "model1.fit(x_train, y_train)\n",
    "y_pred_ef = model1.predict(x_test)\n",
    "\n",
    "print(\"Training Accuracy: \", model1.score(x_train, y_train))\n",
    "print('Testing Accuarcy: ', model1.score(x_test, y_test))\n",
    "cr = classification_report(y_test,  y_pred_ef)\n",
    "print(cr)\n",
    "cm = confusion_matrix(y_test, y_pred_ef)\n",
    "sns.heatmap(cm, annot = True, cmap = 'copper')\n",
    "plt.show()\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "                 \n",
    "model2 = BalancedBaggingClassifier(base_estimator = RandomForestClassifier(),\n",
    "                                 sampling_strategy = 'auto',\n",
    "                                 replacement = False,\n",
    "                                 random_state = 0)\n",
    "\n",
    "model2.fit(x_train, y_train)\n",
    "y_pred_bc = model2.predict(x_test)\n",
    "\n",
    "print(\"Training Accuracy: \", model2.score(x_train, y_train))\n",
    "print('Testing Accuarcy: ', model2.score(x_test, y_test))\n",
    "cr = classification_report(y_test,  y_pred_bc)\n",
    "print(cr)\n",
    "cm = confusion_matrix(y_test, y_pred_bc)\n",
    "sns.heatmap(cm, annot = True, cmap = 'Purples')\n",
    "plt.show()\n",
    "\n",
    "y_pred = y_pred_rf*0.5 + y_pred_ef*0.2 + y_pred_bc*0.3\n",
    "\n",
    "y_pred[y_pred > 0.5] = 1\n",
    "y_pred[y_pred <= 0.5] = 0\n",
    "cr = classification_report(y_test,  y_pred)\n",
    "print(cr)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot = True, cmap = 'Reds')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vote_est = [ \n",
    "    ('brf', BalancedRandomForestClassifier()),\n",
    "    ('bc', BalancedBaggingClassifier()),\n",
    "    ('eec',EasyEnsembleClassifier())]\n",
    "\n",
    "voting = VotingClassifier(estimators = vote_est , voting = 'soft')\n",
    "voting.fit(x_train, y_train)\n",
    "\n",
    "y_pred = voting.predict(x_test).astype(int)\n",
    "cr = classification_report(y_test,  y_pred)\n",
    "print(cr)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot = True, cmap = 'magma')\n",
    "plt.show()\n",
    "\n",
    "y.value_counts()\n",
    "frauds = np.array(data[data['fraud_reported'] == 0].index)\n",
    "no_frauds = len(frauds)\n",
    "print(no_frauds)\n",
    "\n",
    "normal_indices = data[data['fraud_reported'] == 1]\n",
    "no_normal_indices = len(normal_indices)\n",
    "print(no_normal_indices)\n",
    "\n",
    "random_normal_indices = np.random.choice(no_normal_indices, size = no_frauds, replace = True)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "print(len(random_normal_indices))\n",
    "\n",
    "under_sample = np.concatenate([frauds, random_normal_indices])\n",
    "print(len(under_sample))\n",
    "\n",
    "undersample_data = data.iloc[under_sample, :]\n",
    "\n",
    "x_u = undersample_data.iloc[:, undersample_data.columns != 'fraud_reported'] \n",
    "y_u = undersample_data.iloc[:, undersample_data.columns == 'fraud_reported']\n",
    "\n",
    "print(x_u.shape)\n",
    "print(y_u.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x_u, y_u, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(x_train1.shape)\n",
    "print(y_train1.shape)\n",
    "print(x_test1.shape)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train1 = sc.fit_transform(x_train1)\n",
    "x_test1 = sc.transform(x_test1)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_u = RandomForestClassifier()\n",
    "model_u.fit(x_train1, y_train1)\n",
    "\n",
    "y_pred = model_u.predict(x_test1)\n",
    "\n",
    "print(\"Training Accuracy: \", model_u.score(x_train1, y_train1))\n",
    "print('Testing Accuarcy: ', model_u.score(x_test1, y_test1))\n",
    "cm = confusion_matrix(y_test1, y_pred)\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "sns.heatmap(cm, annot = True, cmap = 'winter')\n",
    "plt.show()\n",
    "cr = classification_report(y_test1, y_pred)\n",
    "print(cr)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "x_resample, y_resample  = SMOTE().fit_sample(x, y.values.ravel())\n",
    "\n",
    "print(x_resample.shape)\n",
    "print(y_resample.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x_resample, y_resample, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(x_train2.shape)\n",
    "print(y_train2.shape)\n",
    "print(x_test2.shape)\n",
    "print(y_test2.shape)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train2 = sc.fit_transform(x_train2)\n",
    "x_test2 = sc.transform(x_test2)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_o = RandomForestClassifier()\n",
    "model_o.fit(x_train2, y_train2)\n",
    "\n",
    "y_pred = model_o.predict(x_test2)\n",
    "\n",
    "print(\"Training Accuracy: \", model_o.score(x_train2, y_train2))\n",
    "print('Testing Accuarcy: ', model_o.score(x_test2, y_test2))\n",
    "cm = confusion_matrix(y_test2, y_pred)\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "sns.heatmap(cm, annot = True, cmap = 'winter')\n",
    "plt.show()\n",
    "cr = classification_report(y_test2, y_pred)\n",
    "print(cr)\n",
    "\n",
    "from eli5.sklearn import PermutationImportance\n",
    "perm = PermutationImportance(model, random_state = 0).fit(x_test, y_test)\n",
    "eli5.show_weights(perm, feature_names = x_test.columns.tolist())\n",
    "\n",
    "from pdpbox import pdp, info_plots #for partial plots\n",
    "\n",
    "base_features = x_train.columns.values.tolist()\n",
    "\n",
    "feat_name = 'incident_severity'\n",
    "pdp_dist = pdp.pdp_isolate(model=model, dataset=x_test, model_features = base_features, feature = feat_name)\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, feat_name)\n",
    "plt.show()\n",
    "\n",
    "from pdpbox import pdp, info_plots #for partial plots\n",
    "\n",
    "base_features = x_train.columns.values.tolist()\n",
    "\n",
    "feat_name = 'collision_type'\n",
    "pdp_dist = pdp.pdp_isolate(model=model, dataset=x_test, model_features = base_features, feature = feat_name)\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, feat_name)\n",
    "plt.show()\n",
    "\n",
    "from pdpbox import pdp, info_plots #for partial plots\n",
    "\n",
    "base_features = x_train.columns.values.tolist()\n",
    "\n",
    "feat_name = 'incident_severity'\n",
    "pdp_dist = pdp.pdp_isolate(model=model, dataset=x_test, model_features = base_features, feature = feat_name)\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, feat_name)\n",
    "plt.show()\n",
    "\n",
    "from pdpbox import pdp, info_plots #for partial plots\n",
    "\n",
    "base_features = x_train.columns.values.tolist()\n",
    "\n",
    "feat_name = 'insured_zip'\n",
    "pdp_dist = pdp.pdp_isolate(model=model, dataset=x_test, model_features = base_features, feature = feat_name)\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, feat_name)\n",
    "plt.show()\n",
    "\n",
    "from pdpbox import pdp, info_plots #for partial plots\n",
    "\n",
    "base_features = x_train.columns.values.tolist()\n",
    "\n",
    "feat_name = 'age'\n",
    "pdp_dist = pdp.pdp_isolate(model=model, dataset=x_test, model_features = base_features, feature = feat_name)\n",
    "\n",
    "pdp.pdp_plot(pdp_dist, feat_name)\n",
    "plt.show()\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(x_test)\n",
    "\n",
    "shap.summary_plot(shap_values[1], x_test, plot_type=\"bar\")\n",
    "\n",
    "shap.summary_plot(shap_values[1], x_test)\n",
    "def fraud_analysis(model, fraud):\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(fraud)\n",
    "    shap.initjs()\n",
    "    return shap.force_plot(explainer.expected_value[1], shap_values[1], fraud)\n",
    "\n",
    "fraud = x_test.iloc[1,:].astype(float)\n",
    "fraud_analysis(model, fraud)\n",
    "\n",
    "fraud = x_test.iloc[2,:].astype(float)\n",
    "fraud_analysis(model, fraud)\n",
    "\n",
    "fraud = x_test.iloc[3,:].astype(float)\n",
    "fraud_analysis(model, fraud)\n",
    "\n",
    "fraud = x_test.iloc[4,:].astype(float)\n",
    "fraud_analysis(model, fraud)\n",
    "\n",
    "fraud = x_test.iloc[5,:].astype(float)\n",
    "fraud_analysis(model, fraud)\n",
    "\n",
    "shap_values = explainer.shap_values(x_train.iloc[:50])\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1], x_test.iloc[:50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
