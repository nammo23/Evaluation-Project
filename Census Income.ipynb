{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline\n",
    "cens = pd.read_csv('adult.data', names=['age', 'workclass', 'fnlwgt', 'education', 'education_num', \\\n",
    "                                      'marital_status', 'occupation', 'relationship', 'race', 'sex', \\\n",
    "                                      'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income'])\n",
    "cens.head()\n",
    "cens.info()\n",
    "\n",
    "n_records = cens.shape[0]\n",
    "\n",
    "n_features = cens.shape[1]\n",
    "\n",
    "n_greater_50k = cens[cens['income'] == ' <=50K'].shape[0]\n",
    "\n",
    "n_at_most_50k = cens[cens['income'] == ' >50K'].shape[0]\n",
    "\n",
    "greater_percent =  (n_greater_50k / n_records) * 100\n",
    "\n",
    "print(\"Total number of records: {}\".format(n_records))\n",
    "print(\"Total number of features: {}\".format(n_features))\n",
    "print(\"Individuals making more than $50k: {}\".format(n_greater_50k))\n",
    "print(\"Individuals making at most $50k: {}\".format(n_at_most_50k))\n",
    "print(\"Percentage of individuals making more than $50k: {:.2f}%\".format(greater_percent))\n",
    "\n",
    "cens.drop('education', inplace=True, axis=1)\n",
    "cens.columns.tolist()\n",
    "cens.isna().sum()\n",
    "print(\"Before removing duplicates:\", cens.duplicated().sum())\n",
    "\n",
    "cens = cens[~cens.duplicated()]\n",
    "\n",
    "print(\"After removing duplicates:\", cens.duplicated().sum())\n",
    "\n",
    "cens.sex.value_counts()\n",
    "columns = ['workclass', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country', 'income']\n",
    "for column in columns:\n",
    "    cens[column] = cens[column].str.strip()\n",
    "    \n",
    "cens.sex.value_counts()\n",
    "cens.workclass.value_counts()\n",
    "\n",
    "change_columns = ['workclass', 'occupation', 'native_country']\n",
    "for column in change_columns:\n",
    "        cens[column] = cens[column].replace({'?': 'Unknown'})\n",
    "\n",
    "cens.workclass.value_counts()\n",
    "cens.describe()\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    " \n",
    "ct_counts = cens.groupby(['education_num', 'income']).size()\n",
    "ct_counts = ct_counts.reset_index(name = 'count')\n",
    "ct_counts = ct_counts.pivot(index = 'education_num', columns = 'income', values = 'count').fillna(0)\n",
    "\n",
    "sb.heatmap(ct_counts, annot = True, fmt = '.0f', cbar_kws = {'label' : 'Number of Individuals'})\n",
    "plt.title('Number of People for Education Class relative to Income')\n",
    "plt.xlabel('Income ($)')\n",
    "plt.ylabel('Education Class');\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "ax = sb.barplot(data = cens, x = 'income', y = 'age', hue = 'sex')\n",
    "ax.legend(loc = 8, ncol = 3, framealpha = 1, title = 'Sex')\n",
    "plt.title('Average of Age for Sex relative to Income')\n",
    "plt.xlabel('Income ($)')\n",
    "plt.ylabel('Average of Age');\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "sb.barplot(data=cens, x='income', y='hours_per_week', palette='YlGnBu')\n",
    "plt.title('Average of Hours per Week relative to Income')\n",
    "plt.xlabel('Income ($)')\n",
    "plt.ylabel('Average of Hours per Week');\n",
    "\n",
    "cens_prep = cens.copy()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "numerical = ['age', 'capital_gain', 'capital_loss', 'hours_per_week', 'fnlwgt']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "cens_prep[numerical] = scaler.fit_transform(cens_prep[numerical])\n",
    "cens_prep.sample(3)\n",
    "\n",
    "cens_prep['sex'] = cens_prep.sex.replace({\"Female\": 0, \"Male\": 1})\n",
    "cens_prep['income'] = cens_prep.income.replace({\"<=50K\": 0, \">50K\": 1})\n",
    "\n",
    "cens_prep = pd.get_dummies(cens_prep)\n",
    "encoded = list(cens_prep.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import needed functions\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Partioning the data\n",
    "X = cens_prep.drop('income', axis=1)\n",
    "y = cens_prep['income']\n",
    "\n",
    "# Splitting to training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "models = {}\n",
    "\n",
    "# models with default parameter\n",
    "models['LogisticRegression'] = LogisticRegression()\n",
    "models['RandomForest'] = RandomForestClassifier()\n",
    "models['AdaBoost'] = AdaBoostClassifier()\n",
    "# Cross validation\n",
    "for model_name in models:\n",
    "    model = models[model_name]\n",
    "    results = cross_validate(model, X, y, cv=5, scoring=['accuracy', 'f1'], return_train_score=True)\n",
    "    \n",
    "    print(model_name + \":\")\n",
    "    print(\"Accuracy:\" , 'train: ', results['train_accuracy'].mean(), '| test: ', results['test_accuracy'].mean())\n",
    "    print(\"F1-score:\" , 'train: ', results['train_f1'].mean(), '| test: ', results['test_f1'].mean())\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "results = cross_validate(clf, X_resampled, y_resampled, cv=5, scoring=['accuracy', 'f1'], return_train_score=True)\n",
    "print(\"Accuracy:\" , 'train: ', results['train_accuracy'].mean(), '| test: ', results['test_accuracy'].mean())\n",
    "print(\"F1-score:\" , 'train: ', results['train_f1'].mean(), '| test: ', results['test_f1'].mean())\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cens_conc = cens.copy()\n",
    "for col in cens_conc.columns:\n",
    "    if cens_conc[col].dtypes == 'object':\n",
    "        encoder = LabelEncoder()\n",
    "        cens_conc[col] = encoder.fit_transform(cens_conc[col])\n",
    "\n",
    "Xc = cens_conc.drop('income', axis=1)\n",
    "yc = cens_conc['income']\n",
    "\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(Xc_train, yc_train)\n",
    "\n",
    "print('\\nFeatures Importance:')\n",
    "feat_imp = pd.DataFrame(zip(Xc.columns.tolist(), clf.feature_importances_ * 100), columns=['feature', 'importance'])\n",
    "feat_imp\n",
    "\n",
    "plt.figure(figsize=[20,6])\n",
    "sb.barplot(data=feat_imp, x='feature', y='importance')\n",
    "plt.title('Features Importance', weight='bold', fontsize=20)\n",
    "plt.xlabel('Feature', weight='bold', fontsize=13)\n",
    "plt.ylabel('Importance (%)', weight='bold', fontsize=13);\n",
    "\n",
    "\n",
    "# add annotations\n",
    "impo = feat_imp['importance']\n",
    "locs, labels = plt.xticks()\n",
    "\n",
    "for loc, label in zip(locs, labels):\n",
    "    count = impo[loc]\n",
    "    pct_string = '{:0.2f}%'.format(count)\n",
    "\n",
    "    plt.text(loc, count-0.8, pct_string, ha = 'center', color = 'w', weight='bold')\n",
    "    \n",
    "cens_final = cens.copy()\n",
    "cens_final.head(2)\n",
    "\n",
    "cens_final.drop(['race', 'sex', 'capital_loss', 'native_country'], axis=1, inplace=True)\n",
    "numerical = ['age', 'capital_gain', 'hours_per_week', 'fnlwgt']\n",
    "scaler = MinMaxScaler()\n",
    "cens_final[numerical] = scaler.fit_transform(cens_final[numerical])\n",
    "\n",
    "cens_final['income'] = cens_final.income.replace({\"<=50K\": 0, \">50K\": 1})\n",
    "\n",
    "cens_final = pd.get_dummies(cens_final)\n",
    "\n",
    "Xf = cens_final.drop('income', axis=1)\n",
    "yf = cens_final['income']\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(Xf, yf)\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "results = cross_validate(clf, X_resampled, y_resampled, cv=5, scoring=['accuracy', 'f1'], return_train_score=True)\n",
    "print(\"Accuracy:\" , 'train: ', results['train_accuracy'].mean(), '| test: ', results['test_accuracy'].mean())\n",
    "print(\"F1-score:\" , 'train: ', results['train_f1'].mean(), '| test: ', results['test_f1'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
